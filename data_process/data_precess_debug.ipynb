{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: \n",
    "Author: Chenlong Zhao\n",
    "Date: 2024-08-26\n",
    "Description: This script is a naive version  to preprocess lanes' data and obstacles' data for dlp.\n",
    "\"\"\"\n",
    "import os\n",
    "from itertools import permutations\n",
    "from itertools import product\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import os\n",
    "os.chdir('../')  # pwd to parent\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from argoverse.map_representation.map_api import ArgoverseMap\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from utils import TemporalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features( raw_lane_path: str,\n",
    "              raw_path_obs: str,\n",
    "              frame_to_get: int\n",
    "              )-> Dict:\n",
    "# obs feature extracttion\n",
    "    obs_df = pd.read_csv(raw_path_obs)  \n",
    "    timestamps = list(np.sort(obs_df['frame_idx'].unique()))\n",
    "\n",
    "    if( len(timestamps) < 50):\n",
    "        print('Not Enough Frames!')\n",
    "        return\n",
    "    if(frame_to_get<19):\n",
    "        print('Not Enough History!')\n",
    "        return\n",
    "    if(frame_to_get > len(timestamps) -31):\n",
    "        print('Not Enough Future!')\n",
    "        return \n",
    "### filting 50 frames around frame_to_get\n",
    "    timestamps = timestamps[ frame_to_get - 19: frame_to_get + 31]\n",
    "    print('from to: ',timestamps[0],timestamps[-1]) ## debug message\n",
    "### re-filting obs df in 50 sampled frames\n",
    "    obs_df = obs_df[obs_df['frame_idx'].isin(timestamps)]\n",
    "### history part\n",
    "    historical_timestamps = timestamps[: 20]\n",
    "    historical_obs_df = obs_df[obs_df['frame_idx'].isin(historical_timestamps)] \n",
    "\n",
    "###  actor track id in history time timestamp  \n",
    "    actor_ids = list(historical_obs_df['track_id'].unique())#历史内所有目标的序列ID 是一个包含所有目标 ID 的列表。\n",
    "### filted from 50 frames frame里面都是历史出现过的ID 包含了历史和可能得未来\n",
    "    obs_df = obs_df[obs_df['track_id'].isin(actor_ids)] #保留历史出现过的ID即可\n",
    "    \n",
    "    actor_num = len(actor_ids)\n",
    "    print('actors ids :',actor_ids)\n",
    "\n",
    "    av_df = obs_df[obs_df['object_type'] == 1].iloc #aV frameS\n",
    "    av_index = actor_ids.index(av_df[0]['track_id'])#av  index in actor_ids \n",
    "    agent_index = 1 # nonsense here, just 2\n",
    "\n",
    "    # ready to make the scene centered at AV at now(19) moment\n",
    "    origin = torch.tensor([av_df[19]['rel_x'], av_df[19]['rel_y']], dtype=torch.float)\n",
    "    print('origin, av boost pos:', origin)\n",
    "    av_heading_vector = origin - torch.tensor([av_df[18]['rel_x'], av_df[18]['rel_y']], dtype=torch.float)# attetion head wrt. boost\n",
    "    theta = torch.atan2(av_heading_vector[1], av_heading_vector[0])\n",
    "    print('av theta in boost at 19 stamps ',theta)\n",
    "    rotate_mat = torch.tensor([[torch.cos(theta), -torch.sin(theta)],\n",
    "                               [torch.sin(theta), torch.cos(theta)]])\n",
    "    \n",
    "### initialization features in .pt\n",
    "    x = torch.zeros(actor_num, 50, 2, dtype=torch.float)\n",
    "    edge_index = torch.LongTensor(list(permutations(range(actor_num), 2))).t().contiguous()#(2, N * N-1) Ai-Aj interaction\n",
    "    padding_mask = torch.ones(actor_num, 50, dtype=torch.bool)\n",
    "    bos_mask = torch.zeros(actor_num, 20, dtype=torch.bool)\n",
    "    rotate_angles = torch.zeros(actor_num, dtype=torch.float)\n",
    "    # full frames samples\n",
    "    complete_samples=[] \n",
    "\n",
    "### processing pos by each actor\n",
    "    #an actor_id with a group of actor_df\n",
    "    for actor_id, actor_df in obs_df.groupby('track_id'): \n",
    "        node_idx = actor_ids.index(actor_id)\n",
    "        node_steps = [timestamps.index(timestamp) for timestamp in actor_df['frame_idx']]# 在最原始文件中的 时间戳的位置\n",
    "        print('actor_id : ',actor_id)\n",
    "        print('node_idx : ',node_idx)\n",
    "        print('node_steps : ',node_steps)\n",
    "        padding_mask[node_idx, node_steps] = False\n",
    "        if padding_mask[node_idx, 19]:  \n",
    "            padding_mask[node_idx, 20:] = True \n",
    "        #pos of the selected actor\n",
    "        xy = torch.from_numpy(np.stack([actor_df['rel_x'].values, actor_df['rel_y'].values], axis=-1)).float()\n",
    "        x[node_idx, node_steps] = torch.matmul(xy - origin , rotate_mat)# center with the AV at 19 s\n",
    "        node_historical_steps = list(filter(lambda node_step: node_step < 20, node_steps))\n",
    "        # mark full sample\n",
    "        if len(node_historical_steps) == 20:\n",
    "            print('full node_historical_steps stamps:', node_idx)\n",
    "        if len(node_steps) == 50:\n",
    "            print('full _steps stamps:', node_idx)\n",
    "            complete_samples.append(node_idx)\n",
    "        \n",
    "        if len(node_historical_steps) > 1:  # calculate the heading of the actor (approximately)\n",
    "            heading_vector = x[node_idx, node_historical_steps[-1]] - x[node_idx, node_historical_steps[-2]] # actor heading  wrt. AV\n",
    "            rotate_angles[node_idx] = torch.atan2(heading_vector[1], heading_vector[0])\n",
    "        else:  # make no predictions for the actor if the number of valid time steps is less than 2\n",
    "            padding_mask[node_idx, 20:] = True\n",
    "    print('complete actor index (not id):',complete_samples)\n",
    "    # bos_mask is True if time step t is valid and time step t-1 is invalid\n",
    "    bos_mask[:, 0] = ~padding_mask[:, 0]# nonsense\n",
    "    bos_mask[:, 1: 20] = padding_mask[:, : 19] & ~padding_mask[:, 1: 20] #\n",
    "    positions = x.clone()#差分前， 保留原始轨迹位置，以AV为中心\n",
    "\n",
    "### differential vector\n",
    "\n",
    "    # gt future wrt. x(19)\n",
    "    x[:, 20:] = torch.where((padding_mask[:, 19].unsqueeze(-1) | padding_mask[:, 20:]).unsqueeze(-1),\n",
    "                            torch.zeros(actor_num, 30, 2),\n",
    "                            x[:, 20:] - x[:, 19].unsqueeze(-2))#torch.where(condition, x_if_true, x_if_false)\n",
    "    # past wrt. past.shift(-1)\n",
    "    x[:, 1: 20] = torch.where((padding_mask[:, : 19] | padding_mask[:, 1: 20]).unsqueeze(-1),\n",
    "                              torch.zeros(actor_num, 19, 2),\n",
    "                              x[:, 1: 20] - x[:, : 19])\n",
    "    x[:, 0] = torch.zeros(actor_num, 2)\n",
    "\n",
    "    # get lane features at the current time step\n",
    "    df_19 = obs_df[obs_df['frame_idx'] == timestamps[19]]# \n",
    "    node_inds_19 = [actor_ids.index(actor_id) for actor_id in df_19['track_id']]# 当前时刻所有actors\n",
    "    node_positions_19 = torch.from_numpy(np.stack([df_19['rel_x'].values, df_19['rel_y'].values], axis=-1)).float()\n",
    "    node_positions_rel = torch.matmul(node_positions_19 - origin, rotate_mat).float()\n",
    "    # gt\n",
    "    y = x[:, 20:] \n",
    "\n",
    "### lanes info file \n",
    "    lanes_df = pd.read_csv(raw_lane_path)\n",
    "    num_rows = lanes_df.shape[0]\n",
    "    num_columns = lanes_df.shape[1]\n",
    "    target_lanes_df =   lanes_df[lanes_df['frame_idx'] ==   timestamps[19] ].iloc\n",
    "\n",
    "    lane_idx_start =  3 # depends on file format\n",
    "    # select lanes points  by x y respt.\n",
    "    x_pos = target_lanes_df[:, range(lane_idx_start, num_columns, 2)]\n",
    "    y_pos = target_lanes_df[:, range(lane_idx_start + 1 , num_columns, 2)]\n",
    "### re-organize points by numpy\n",
    "    x_pos_np = x_pos.to_numpy() # m * n\n",
    "    y_pos_np = y_pos.to_numpy()\n",
    "    print('first 5 x lanes pos: ')\n",
    "    print((x_pos_np[:,:5]))\n",
    "    print('first 5 y lanes pos: ')\n",
    "    print((y_pos_np[:,:5]))\n",
    "\n",
    "    #################### before difference, get raw lane points to convert to boost and  draw after inteference #########################\n",
    "    raw_one_x = np.hstack(x_pos_np)# flatten multi-lanes' x to one dimension \n",
    "    raw_one_y = np.hstack(y_pos_np)# 1 * m*n\n",
    "    raw_lane_pos  = np.vstack((raw_one_x, raw_one_y))## combine 2 * (m*n)\n",
    "    raw_lane_pos = torch.from_numpy(raw_lane_pos).float()\n",
    "    # convert to boost coordinate\n",
    "    raw_lane_pos = raw_lane_pos.permute(1,0)#  (m*n) * 2\n",
    "    inv_rotate_mat = rotate_mat.t()\n",
    "    raw_lane_pos[:] = torch.matmul(raw_lane_pos[:],inv_rotate_mat) + origin\n",
    "    #################### before difference, get raw lane points to store and draw after inteference #########################\n",
    "\n",
    "\n",
    "    #################### before concatenate , get each lane's diff vector  to store  #########################\n",
    "    vector_x_pos_np = x_pos_np[:,1:] - x_pos_np[:,:-1] \n",
    "    vector_y_pos_np = y_pos_np[:,1:] - y_pos_np[:,:-1]# m * (n-1)\n",
    "    one_vx = np.hstack(vector_x_pos_np) # # flatten multi-lanes' vector x to one dimension \n",
    "    one_vy = np.hstack(vector_y_pos_np)\n",
    "    lane_vector_np  = np.vstack((one_vx, one_vy)) #combine 2 * (m * (n-1) )\n",
    "\n",
    "    lane_vectors = torch.from_numpy(lane_vector_np).float()\n",
    "    lane_vectors = lane_vectors.permute(1,0) #   (m * (n-1) ) * 2\n",
    "    print('lane_vectors.shape is ', lane_vectors.shape)\n",
    "    #################### before concatenate , get each lane's diff vector  to store  #########################\n",
    "\n",
    "\n",
    "    head_raw_one_x = np.hstack(x_pos_np[:,:-1])## regard the vector start point as lanes_position, dimension is as the vec\n",
    "    head_raw_one_y = np.hstack(y_pos_np[:,:-1])\n",
    "    lanes_position_np  = np.vstack((head_raw_one_x, head_raw_one_y))\n",
    "    lanes_position = torch.from_numpy(lanes_position_np).float()\n",
    "    lanes_position = lanes_position.permute(1,0)# 2 * (m * (n-1) )\n",
    "    \n",
    "### get lanes map for all actors\n",
    "    ones_tensor = torch.ones(lane_vectors.shape[0])\n",
    "    is_intersections = ones_tensor == 0 # default false\n",
    "    turn_directions = torch.zeros(lane_vectors.shape[0]) # none\n",
    "    traffic_controls =  ones_tensor == 0 # default false\n",
    "    #AL interaction\n",
    "    lane_actor_index = torch.LongTensor(list(product(torch.arange(lane_vectors.size(0)), node_inds_19))).t().contiguous()# diff data type\n",
    "    #AL vectors at every point to every actor\n",
    "    lane_actor_vectors = \\\n",
    "        lanes_position.repeat_interleave(len(node_inds_19), dim=0) - node_positions_rel.repeat(lane_vectors.size(0), 1)\n",
    "    mask = torch.norm(lane_actor_vectors, p=2, dim=-1) < 50 # \n",
    "    lane_actor_index = lane_actor_index[:, mask]\n",
    "    lane_actor_vectors = lane_actor_vectors[mask]\n",
    "\n",
    "\n",
    "### file name index\n",
    "    seq_id = str(frame_to_get)\n",
    "# L = (m * (n-1) )\n",
    "    return  {\n",
    "        'x': x[:, : 20],  # [N, 20, 2] \n",
    "        'positions': positions,  # [N, 50, 2]   \n",
    "        'edge_index': edge_index,  # [2, N x N - 1]\n",
    "        'y': y,  # [N, 30, 2]\n",
    "        'num_nodes': actor_num,\n",
    "        'padding_mask': padding_mask,  # [N, 50]\n",
    "        'bos_mask': bos_mask,  # [N, 20]\n",
    "        'rotate_angles': rotate_angles,  # [N]\n",
    "        'lane_vectors': lane_vectors,  # [L, 2]\n",
    "        'is_intersections': is_intersections,  # [L]\n",
    "        'turn_directions': turn_directions,  # [L]\n",
    "        'traffic_controls': traffic_controls,  # [L]\n",
    "        'lane_actor_index': lane_actor_index,  # [2, E_{A-L}]\n",
    "        'lane_actor_vectors': lane_actor_vectors,  # [E_{A-L}, 2]\n",
    "        'seq_id': int(seq_id),\n",
    "        'av_index': av_index,\n",
    "        'agent_index': agent_index,\n",
    "        'city': 'HeFei',\n",
    "        'origin': origin.unsqueeze(0),\n",
    "        'theta': theta,\n",
    "        'raw_lane_pos': raw_lane_pos, #n*2\n",
    "        'complete_samples': complete_samples\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from to:  60 109\n",
      "actors ids : [-1, 301]\n",
      "origin, av boost pos: tensor([-8579.7607,   385.0659])\n",
      "av theta in boost at 19 stamps  tensor(-1.3737)\n",
      "actor_id :  -1\n",
      "node_idx :  0\n",
      "node_steps :  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "full node_historical_steps stamps: 0\n",
      "full _steps stamps: 0\n",
      "actor_id :  301\n",
      "node_idx :  1\n",
      "node_steps :  [19, 20, 21, 22, 23, 24, 25, 26]\n",
      "complete actor index (not id): [0]\n",
      "first 5 x lanes pos: \n",
      "[[-48.02824905 -46.03077682 -44.03334021 -42.03594159 -40.03854101]\n",
      " [-48.13082304 -46.13499609 -44.13956562 -42.14418296 -40.14849942]]\n",
      "first 5 y lanes pos: \n",
      "[[ 2.0343823   1.93409652  1.833097    1.73124938  1.62934963]\n",
      " [-1.71224323 -1.83875144 -1.97399737 -2.11124033 -2.24373965]]\n",
      "lane_vectors.shape is  torch.Size([248, 2])\n",
      "from to:  67 116\n",
      "actors ids : [-1, 301]\n",
      "origin, av boost pos: tensor([-8577.3076,   373.6706])\n",
      "av theta in boost at 19 stamps  tensor(-1.3517)\n",
      "actor_id :  -1\n",
      "node_idx :  0\n",
      "node_steps :  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "full node_historical_steps stamps: 0\n",
      "full _steps stamps: 0\n",
      "actor_id :  301\n",
      "node_idx :  1\n",
      "node_steps :  [12, 13, 14, 15, 16, 17, 18, 19]\n",
      "complete actor index (not id): [0]\n",
      "first 5 x lanes pos: \n",
      "[[-48.38733378 -46.39083392 -44.39451043 -42.39835702 -40.40225186]\n",
      " [-48.47176416 -46.47462649 -44.47725143 -42.4797406  -40.48222734]]\n",
      "first 5 y lanes pos: \n",
      "[[ 2.13641432  2.01824096  1.89710802  1.77309591  1.6482447 ]\n",
      " [-1.75957422 -1.86680077 -1.97042931 -2.07150729 -2.17202467]]\n",
      "lane_vectors.shape is  torch.Size([248, 2])\n"
     ]
    }
   ],
   "source": [
    "target_frame=[ 79, 86]\n",
    "for i in target_frame:\n",
    "    frame_to_get = i\n",
    "    kwargs = get_features(raw_lane_path='/home/alon/Learning/HiVT/mini_data/2024-08-26-01-32-14_lanes.csv',\n",
    "            raw_path_obs = '/home/alon/Learning/HiVT/mini_data/2024-08-26-01-32-14_obs.csv',\n",
    "            frame_to_get = frame_to_get )\n",
    "    _data = TemporalData(**kwargs)#封装成自定义数据类型\n",
    "    torch.save(_data, os.path.join('/home/alon/Learning/HiVT/mini_data/curve_data', str(kwargs['seq_id']) + '.pt'))# 根据目录存为pt文件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HiVT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
